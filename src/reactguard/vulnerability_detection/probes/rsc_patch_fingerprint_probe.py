from __future__ import annotations

"""
ReactGuard, framework- and vulnerability-detection tooling for CVE-2025-55182 (React2Shell).
Copyright (C) 2025  Theori Inc.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Affero General Public License as published
by the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Affero General Public License for more details.

You should have received a copy of the GNU Affero General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""

"""Next.js Server Action discovery and probe helpers."""

import html
import json
import re
import secrets
from collections.abc import Iterable
from typing import Any
from urllib.parse import urlparse

from ...config import load_http_settings
from ...http.crawl import crawl_same_origin_html
from ...http.models import HttpRequest, RetryConfig
from ...http.retry import send_with_retries
from ...http.url import build_endpoint_candidates
from ...http.utils import get_http_client
from ...utils.context import get_scan_context, scan_context


def _user_agent() -> str:
    return load_http_settings().user_agent


def _scan_once(
    url: str,
    *,
    method: str = "GET",
    headers: dict[str, str] | None = None,
    body: str | bytes | None = None,
    timeout: float | None = None,
    allow_redirects: bool = True,
    http_client=None,
) -> dict[str, Any]:
    """
    Issue a single HTTP request (no retries) and return a request_with_retries-compatible mapping.

    These probes are intended to be deterministic and bounded.
    """
    settings = load_http_settings()
    context = get_scan_context()
    request_headers = dict(headers or {})
    request_headers.setdefault("User-Agent", settings.user_agent)
    client = http_client or context.http_client or get_http_client()
    effective_timeout = timeout if timeout is not None else (context.timeout if context.timeout is not None else settings.timeout)

    request = HttpRequest(
        url=url,
        method=method,
        headers=request_headers,
        body=body,
        timeout=effective_timeout,
        allow_redirects=allow_redirects,
    )

    response = send_with_retries(
        client,
        request,
        retry_config=RetryConfig(max_attempts=1),
    )

    result: dict[str, Any] = {
        "ok": response.ok,
        "status_code": response.status_code,
        "headers": response.headers,
        "body": response.text,
        "body_snippet": response.body_snippet,
        "url": response.url or url,
        "error_message": response.error_message,
        "error_type": response.error_type,
        "meta": dict(response.meta or {}),
    }
    if result.get("ok") is False and result.get("error_message") and result.get("error") is None:
        result["error"] = result["error_message"]
    return result


def _build_multipart_body(parts: Iterable[tuple[str, str]]) -> tuple[str, str]:
    boundary = f"----FormBoundary{secrets.token_hex(8)}"
    body = ""
    for name, value in parts:
        body += f'--{boundary}\r\nContent-Disposition: form-data; name="{name}"\r\n\r\n{value}\r\n'
    body += f"--{boundary}--\r\n"
    return boundary, body


def _send_multipart(
    url: str,
    *,
    action_id: str,
    parts: Iterable[tuple[str, str]],
    timeout: float | None,
    http_client=None,
) -> dict[str, Any]:
    boundary, body = _build_multipart_body(parts)
    headers = {
        "Content-Type": f"multipart/form-data; boundary={boundary}",
        "Accept": "text/x-component",
        "Next-Action": action_id,
        "User-Agent": _user_agent(),
    }
    scan = _scan_once(
        url,
        method="POST",
        headers=headers,
        body=body,
        timeout=timeout,
        http_client=http_client,
    )
    scan.setdefault("action_id", action_id)
    return scan


_NEXT_ACTION_VALUE_BEFORE_NAME_RE = re.compile(r'value=[\'"]([^\'"]+)[\'"][^>]*name=[\'"]\\$ACTION_[^\'"]+[\'"]')
_NEXT_ACTION_NAME_BEFORE_VALUE_RE = re.compile(r'name=[\'"]\\$ACTION_[^\'"]+[\'"][^>]*value=[\'"]([^\'"]+)[\'"]')
_NEXT_ACTION_JSON_ID_RE = re.compile(r'"id"\\s*:\\s*"([^"]+)"')
_NEXT_ACTION_ESCAPED_ID_RE = re.compile(r"&quot;id&quot;:&quot;([^&]+)&quot;")


def _extract_nextjs_action_id_from_html(html_text: str) -> str | None:
    if not html_text:
        return None

    # Fast path: look for the escaped JSON payload in the `$ACTION_*` hidden input value.
    match = _NEXT_ACTION_ESCAPED_ID_RE.search(html_text)
    if match:
        return match.group(1)

    for regex in (_NEXT_ACTION_NAME_BEFORE_VALUE_RE, _NEXT_ACTION_VALUE_BEFORE_NAME_RE):
        match = regex.search(html_text)
        if not match:
            continue

        raw_value = html.unescape(match.group(1)).strip()
        if not raw_value:
            continue

        try:
            parsed = json.loads(raw_value)
            if isinstance(parsed, dict) and parsed.get("id"):
                return str(parsed["id"])
        except Exception:
            fallback = _NEXT_ACTION_JSON_ID_RE.search(raw_value)
            if fallback:
                return fallback.group(1)

    return None


_NEXT_ACTION_HEADER_LITERAL_RE = re.compile(r'["\']next-action["\']\s*:\s*["\']([^"\']+)["\']', re.IGNORECASE)
_NEXT_ACTION_HEADER_SET_RE = re.compile(r'\.set\(\s*["\']next-action["\']\s*,\s*["\']([^"\']+)["\']\s*\)', re.IGNORECASE)
_NEXT_ACTION_HEADER_APPEND_RE = re.compile(r'\.append\(\s*["\']next-action["\']\s*,\s*["\']([^"\']+)["\']\s*\)', re.IGNORECASE)
_NEXT_ACTION_HEADER_BRACKET_RE = re.compile(r'\[\s*["\']next-action["\']\s*\]\s*=\s*["\']([^"\']+)["\']', re.IGNORECASE)

_SCRIPT_SRC_RE = re.compile(r"<script[^>]+src=[\"']([^\"']+)[\"']", re.IGNORECASE)
_LINK_HREF_RE = re.compile(r"<link[^>]+href=[\"']([^\"']+)[\"']", re.IGNORECASE)
_IMPORT_CALL_RE = re.compile(r'import\(\s*["\']([^"\']+)["\']\s*\)', re.IGNORECASE)


def _same_origin(a: str, b: str) -> bool:
    pa = urlparse(a)
    pb = urlparse(b)
    return (pa.scheme, pa.netloc) == (pb.scheme, pb.netloc)


def _looks_like_js_asset(path: str) -> bool:
    if not path:
        return False
    candidate = str(path).split("?", 1)[0].split("#", 1)[0].lower()
    return candidate.endswith((".js", ".mjs", ".ts", ".tsx", ".jsx"))


def _extract_next_action_header_ids(text: str) -> list[str]:
    if not text:
        return []

    candidates: list[str] = []
    for regex in (
        _NEXT_ACTION_HEADER_LITERAL_RE,
        _NEXT_ACTION_HEADER_SET_RE,
        _NEXT_ACTION_HEADER_APPEND_RE,
        _NEXT_ACTION_HEADER_BRACKET_RE,
    ):
        for match in regex.finditer(text):
            value = (match.group(1) or "").strip()
            if not value:
                continue
            if any(ch.isspace() for ch in value):
                continue
            if len(value) > 512:
                continue
            candidates.append(value)

    # De-dupe while preserving order.
    return list(dict.fromkeys(candidates))


def discover_next_action_ids(
    url: str,
    *,
    timeout: float | None = None,
    http_client=None,
    max_pages: int | None = None,
    max_depth: int | None = None,
    max_assets: int = 20,
) -> list[str]:
    """
    Best-effort discovery of valid `Next-Action` IDs from same-origin content.

    Sources (GET-only, bounded, landing-page only):
    - Next.js `$ACTION_*` hidden input payloads in HTML
    - Literal `Next-Action` header values embedded in inline scripts / JS bundles
    """
    if not url:
        return []

    if http_client is not None:
        with scan_context(http_client=http_client):
            return discover_next_action_ids(
                url,
                timeout=timeout,
                http_client=None,
                max_pages=max_pages,
                max_depth=max_depth,
                max_assets=max_assets,
            )

    action_ids: list[str] = []
    asset_urls: list[str] = []

    effective_max_pages = 6 if max_pages is None else max_pages
    effective_max_depth = 2 if max_depth is None else max_depth
    pages = crawl_same_origin_html(
        url,
        timeout=timeout,
        http_client=http_client,
        max_pages=effective_max_pages,
        max_depth=effective_max_depth,
    )
    origin_url = pages[0].url if pages else url
    for page in pages:
        body = page.body or ""
        if not body:
            continue

        next_id = _extract_nextjs_action_id_from_html(body)
        if next_id:
            action_ids.append(next_id)

        action_ids.extend(_extract_next_action_header_ids(body))

        for regex in (_SCRIPT_SRC_RE, _LINK_HREF_RE, _IMPORT_CALL_RE):
            for match in regex.finditer(body):
                raw = (match.group(1) or "").strip()
                if not raw:
                    continue
                if raw.startswith(("data:", "javascript:", "mailto:", "tel:")):
                    continue
                if raw.startswith(("http://", "https://")):
                    # Only follow same-origin absolute URLs.
                    if not _same_origin(origin_url, raw):
                        continue
                    candidate_urls = [raw]
                else:
                    # Support both root-relative and base-relative paths.
                    candidate_urls = build_endpoint_candidates(page.url or url, raw)
                for candidate_url in candidate_urls:
                    if not candidate_url or not _same_origin(origin_url, candidate_url):
                        continue
                    asset_urls.append(candidate_url)

    asset_urls = list(dict.fromkeys([u for u in asset_urls if u]))
    js_assets = [u for u in asset_urls if _looks_like_js_asset(u)]

    for asset_url in js_assets[:max_assets]:
        resp = _scan_once(
            asset_url,
            method="GET",
            headers={"Accept": "application/javascript, text/javascript, */*"},
            timeout=timeout,
            allow_redirects=True,
            http_client=http_client,
        )
        if not resp.get("ok"):
            continue
        body = str(resp.get("body") or resp.get("body_snippet") or "")
        if not body:
            continue
        action_ids.extend(_extract_next_action_header_ids(body))

    # De-dupe while preserving order.
    return list(dict.fromkeys([a for a in action_ids if a]))


def discover_nextjs_action_id(
    url: str,
    *,
    timeout: float | None = None,
    http_client=None,
) -> str | None:
    """
    Best-effort extraction of a valid Next.js Server Action ID from the rendered HTML.

    Next.js Server Actions require a valid `Next-Action` header. When scanning in a lab we can scrape an
    action ID from the server-rendered form payload (hidden `$ACTION_*` inputs).
    """
    result = _scan_once(
        url,
        method="GET",
        headers={"Accept": "text/html, */*"},
        timeout=timeout,
        http_client=http_client,
    )
    body = str(result.get("body") or result.get("body_snippet") or "")
    return _extract_nextjs_action_id_from_html(body)


def discover_nextjs_action_entrypoint(
    url: str,
    *,
    timeout: float | None = None,
    http_client=None,
    max_pages: int | None = None,
    max_depth: int | None = None,
) -> tuple[str, str] | None:
    """
    Discover a (page_url, action_id) pair for Next.js Server Actions.

    Attempts to find a (page_url, action_id) pair by scanning the landing page (after redirects).

    Note: link-following crawls are intentionally disabled by default to avoid probing arbitrary
    app pages. If action forms are not present on the landing page, this may return None.
    """
    if not url:
        return None

    if http_client is not None:
        with scan_context(http_client=http_client):
            return discover_nextjs_action_entrypoint(
                url,
                timeout=timeout,
                http_client=None,
                max_pages=max_pages,
                max_depth=max_depth,
            )

    effective_max_pages = 6 if max_pages is None else max_pages
    effective_max_depth = 2 if max_depth is None else max_depth
    pages = crawl_same_origin_html(url, timeout=timeout, http_client=http_client, max_pages=effective_max_pages, max_depth=effective_max_depth)
    for page in pages:
        if not page.body:
            continue
        action_id = _extract_nextjs_action_id_from_html(page.body)
        if action_id:
            return page.url, action_id
    return None


def _nextjs_default_prev_state() -> dict[str, Any]:
    # Minimal ActionState shape for our Next.js lab Server Actions (useActionState-like signatures).
    # Keep this stable so probes remain deterministic across containers.
    return {
        "status": "reactguard probe",
        "queueLength": 0,
        "recent": [],
        "lastDetail": "",
    }


def send_nextjs_proto_probe(
    url: str,
    *,
    action_id: str,
    server_ref_marker: str = "F",
    timeout: float | None = 5.0,
    http_client=None,
) -> dict[str, Any]:
    """
    Next.js Server Action proto probe for CVE-2025-55182.

    Keeps typical two-argument actions successful by sending (prevState, formData) first and placing the
    proto traversal payload as a third argument so it is deserialized but usually ignored by app code.
    """
    if not action_id:
        raise ValueError("action_id is required for Next.js Server Action probes")
    if server_ref_marker not in {"F", "h"}:
        raise ValueError("server_ref_marker must be 'F' or 'h'")

    parts = [
        ("1", json.dumps(_nextjs_default_prev_state())),
        ("4", json.dumps({"x": {}})),
        ("3_title", "reactguard-probe"),
        ("0", json.dumps(["$1", "$K3", f"${server_ref_marker}4:x:__proto__"])),
    ]
    if http_client is not None:
        with scan_context(http_client=http_client):
            return _send_multipart(url, action_id=action_id, parts=parts, timeout=timeout, http_client=http_client)
    return _send_multipart(url, action_id=action_id, parts=parts, timeout=timeout, http_client=http_client)


def send_nextjs_control_probe(
    url: str,
    *,
    action_id: str,
    server_ref_marker: str = "F",
    timeout: float | None = 5.0,
    http_client=None,
) -> dict[str, Any]:
    """Next.js control probe paired with `send_nextjs_proto_probe` (uses a random safe property path)."""
    if not action_id:
        raise ValueError("action_id is required for Next.js Server Action probes")
    if server_ref_marker not in {"F", "h"}:
        raise ValueError("server_ref_marker must be 'F' or 'h'")

    safe_prop = f"z{secrets.token_hex(4)}"
    parts = [
        ("1", json.dumps(_nextjs_default_prev_state())),
        ("4", json.dumps({"x": {}})),
        ("3_title", "reactguard-probe"),
        ("0", json.dumps(["$1", "$K3", f"${server_ref_marker}4:x:{safe_prop}"])),
    ]
    if http_client is not None:
        with scan_context(http_client=http_client):
            return _send_multipart(url, action_id=action_id, parts=parts, timeout=timeout, http_client=http_client)
    return _send_multipart(url, action_id=action_id, parts=parts, timeout=timeout, http_client=http_client)


__all__ = [
    "discover_nextjs_action_id",
    "discover_next_action_ids",
    "discover_nextjs_action_entrypoint",
    "send_nextjs_proto_probe",
    "send_nextjs_control_probe",
]
