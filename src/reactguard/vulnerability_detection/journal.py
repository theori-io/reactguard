# SPDX-FileCopyrightText: 2025 Theori Inc.
# SPDX-License-Identifier: AGPL-3.0-or-later

"""Lightweight journal helper for PoC evaluations."""

import json
from collections.abc import Iterator
from contextlib import contextmanager
from contextvars import ContextVar
from typing import Any

from ..http.headers import header_value


class PocJournal:
    """Structured journal for PoC runs with size-aware serialization."""

    def __init__(self, entry_limit_bytes: int = 8192, max_entries: int = 128):
        self.entry_limit_bytes = entry_limit_bytes
        self.max_entries = max_entries
        self.entries: list[dict[str, Any]] = []

    def add_event(
        self,
        step: str,
        summary: str,
        *,
        outcome: str | None = None,
        data: Any | None = None,
        status_code: int | None = None,
    ) -> None:
        entry: dict[str, Any] = {"step": step, "summary": summary}
        if outcome is not None:
            entry["outcome"] = outcome
        if status_code is not None:
            entry["status_code"] = status_code
        if data is not None:
            entry["data"] = self._normalize_data(data)
        self.entries.append(entry)

    def add_probe(
        self,
        label: str,
        *,
        action_id: str | None = None,
        endpoint: str | None = None,
        status_code: int | None = None,
        body_snippet: str = "",
        headers: dict[str, Any] | None = None,
        digest: str | None = None,
    ) -> None:
        target = action_id or endpoint or "unknown"
        summary = f"{label} probe for {target} returned {status_code}"
        probe_data: dict[str, Any] = {
            "body_snippet": (body_snippet or "")[:4096],
        }
        if action_id:
            probe_data["action_id"] = action_id
        if endpoint:
            probe_data["endpoint"] = endpoint
        content_type = header_value(headers or {}, "content-type")
        if content_type:
            probe_data["content_type"] = content_type
        if digest:
            probe_data["digest"] = digest

        self.add_event(
            "probe",
            summary,
            status_code=status_code,
            data=probe_data,
        )

    def add_decision(self, outcome: str, reason: str) -> None:
        self.add_event("decision", reason, outcome=outcome)

    def to_list(self) -> list[dict[str, Any]]:
        serialized: list[dict[str, Any]] = []
        for entry in self.entries[: self.max_entries]:
            trimmed = self._trim_entry(entry)
            trimmed = self._enforce_entry_limit(trimmed)
            serialized.append(trimmed)

        if len(self.entries) > self.max_entries:
            serialized.append(
                {
                    "step": "journal-truncated",
                    "summary": f"Journal truncated at {self.max_entries} entries",
                    "dropped_entries": len(self.entries) - self.max_entries,
                }
            )

        return serialized

    def _normalize_data(self, data: Any) -> Any:
        if isinstance(data, str):
            return data[: self.entry_limit_bytes]
        if isinstance(data, dict):
            return {key: self._normalize_data(value) for key, value in data.items()}
        if isinstance(data, list):
            return [self._normalize_data(item) for item in data][: self.max_entries]
        try:
            serialized = json.dumps(data, ensure_ascii=True)
            return serialized[: self.entry_limit_bytes]
        except Exception:
            return str(data)[: self.entry_limit_bytes]

    def _trim_entry(self, entry: dict[str, Any]) -> dict[str, Any]:
        trimmed: dict[str, Any] = {}
        for key, value in entry.items():
            if key == "data" and isinstance(value, str):
                trimmed[key] = value[: self.entry_limit_bytes]
            else:
                trimmed[key] = value
        return trimmed

    def _enforce_entry_limit(self, entry: dict[str, Any]) -> dict[str, Any]:
        serialized = json.dumps(entry, ensure_ascii=True)
        if len(serialized) <= self.entry_limit_bytes:
            return entry

        trimmed = dict(entry)
        data = trimmed.get("data")

        if isinstance(data, str):
            base = dict(trimmed)
            base.pop("data", None)
            base_size = len(json.dumps(base, ensure_ascii=True))
            allowance = max(0, self.entry_limit_bytes - base_size - 10)
            trimmed["data"] = data[:allowance]
        else:
            trimmed.pop("data", None)

        if len(json.dumps(trimmed, ensure_ascii=True)) > self.entry_limit_bytes:
            return {"step": "journal-entry-truncated", "summary": "Entry exceeded size limit"}

        return trimmed


_current_journal: ContextVar[PocJournal | None] = ContextVar("reactguard_poc_journal", default=None)


def get_current_journal() -> PocJournal | None:
    """Return the ambient PoC journal when set."""
    return _current_journal.get()


@contextmanager
def journal_context(journal: PocJournal | None = None) -> Iterator[PocJournal]:
    """
    Context manager that sets an ambient PoC journal for nested helpers.

    When ``journal`` is None, reuses any outer ambient journal or creates a new one.
    """
    current = get_current_journal()
    effective = journal or current or PocJournal()
    token = _current_journal.set(effective)
    try:
        yield effective
    finally:
        _current_journal.reset(token)


__all__ = ["PocJournal", "get_current_journal", "journal_context"]
