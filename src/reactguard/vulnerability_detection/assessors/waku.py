"""
ReactGuard, framework- and vulnerability-detection tooling for CVE-2025-55182 (React2Shell).
Copyright (C) 2025  Theori Inc.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Affero General Public License as published
by the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Affero General Public License for more details.

You should have received a copy of the GNU Affero General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""

"""Waku assessor for CVE-2025-55182."""

import secrets
from typing import Any
from urllib.parse import urlparse

from ...framework_detection.signals.waku import probe_waku_server_actions_result
from ...http.crawl import crawl_same_origin_html
from ...http.url import build_endpoint_candidates
from ..constants import MAX_WAKU_PROBE_ENDPOINTS
from ..interpreters import analyze_waku_results
from ..journal import PocJournal, get_current_journal
from ..probes.waku_probe import send_waku_probe
from .base import BaseAssessor


class WakuAssessor(BaseAssessor):
    framework_name = "waku"

    def evaluate(
        self,
        base_url: str,
        detected_versions: dict[str, Any],
        detect_context: dict | None = None,
    ) -> dict[str, Any]:
        detect_context = self._resolve_detect_context(detect_context)
        journal = get_current_journal() or PocJournal()
        signals = (detect_context or {}).get("signals", {}) or {}
        react_version = detected_versions.get("react_version") or detected_versions.get("detected_react_version")
        react_major_confidence = (detect_context or {}).get("react_major_confidence") or self.get_version_confidence(
            "react_version",
            detected_versions,
            detect_context,
        )

        endpoints: list[tuple[str, str]] = []
        has_actions = False
        error_info: dict[str, Any] | None = None

        def _infer_action_name(endpoint_url: str) -> str:
            try:
                path = urlparse(endpoint_url).path
                leaf = path.rstrip("/").split("/")[-1]
                return leaf.split(".", 1)[0]
            except Exception:
                return ""

        # Prefer framework-detected endpoints when available (avoids duplicated discovery work).
        detected_endpoints = list((detect_context or {}).get("server_action_endpoints") or [])
        for endpoint in detected_endpoints:
            if not endpoint:
                continue
            action_name = _infer_action_name(str(endpoint))
            endpoint_str = str(endpoint)
            if endpoint_str.startswith(("http://", "https://")):
                endpoints.append((endpoint_str, action_name))
                continue
            for candidate in build_endpoint_candidates(base_url, endpoint_str):
                endpoints.append((candidate, action_name))

        if endpoints:
            has_actions = True
        else:
            probe = probe_waku_server_actions_result(base_url)
            has_actions = probe.has_actions
            if probe.endpoints:
                for endpoint_path, action_name in probe.endpoints:
                    for candidate in build_endpoint_candidates(base_url, endpoint_path):
                        endpoints.append((candidate, action_name))
            if probe.error_info:
                error_info = probe.error_info

        if endpoints:
            endpoints = list(dict.fromkeys(endpoints))
            # Prefer explicit server action endpoints when available. Older Waku builds may only
            # expose route-level RSC endpoints like `/RSC/index.txt`, so keep those as fallback.
            explicit_action_endpoints = [(endpoint_url, action_name) for endpoint_url, action_name in endpoints if "/RSC/F/" in endpoint_url or "/RSC/ACTION_" in endpoint_url]
            if explicit_action_endpoints:
                endpoints = explicit_action_endpoints

        if (not has_actions or not endpoints) and error_info and error_info.get("error_message"):
            return self.build_inconclusive_result(
                str(error_info.get("error_message") or ""),
                detected_versions,
                journal=journal,
                confidence=signals.get("detection_confidence_level") or "low",
                error_message=str(error_info.get("error_message") or ""),
                error_type=str(error_info.get("error_type") or ""),
            )

        if (not has_actions or not endpoints) and base_url:
            for page in crawl_same_origin_html(
                base_url,
                follow_links=True,
            ):
                if not page.url or page.url == base_url:
                    continue
                probe = probe_waku_server_actions_result(page.url)
                has_actions = probe.has_actions
                if probe.endpoints:
                    endpoints = []
                    for endpoint_path, action_name in probe.endpoints:
                        for candidate in build_endpoint_candidates(page.url, endpoint_path):
                            endpoints.append((candidate, action_name))
                    if endpoints:
                        endpoints = list(dict.fromkeys(endpoints))
                if has_actions and endpoints:
                    journal.add_event(
                        "waku-discovery",
                        "Discovered Waku action endpoints via bounded crawl",
                        data={"entrypoint_url": page.url, "endpoints": len(endpoints)},
                    )
                    break

        if not has_actions or not endpoints:
            return self.build_not_applicable_result(
                "No Waku server action endpoints found",
                detected_versions,
                surface_detected=False,
                journal=journal,
                confidence=signals.get("detection_confidence_level") or "medium",
                framework=self.framework_name,
                decode_surface_reached=False,
            )

        # Limit probes to avoid excessive requests
        endpoints_to_probe = endpoints[:MAX_WAKU_PROBE_ENDPOINTS]
        probe_results: list[dict[str, Any]] = []

        control_results: list[dict[str, Any]] = []

        for endpoint_url, action_name in endpoints_to_probe:
            proto_result: dict[str, Any] = dict(
                send_waku_probe(
                    endpoint_url,
                    target_prop="__proto__",
                    force_fail=True,
                )
            )
            control_result: dict[str, Any] = dict(
                send_waku_probe(
                    endpoint_url,
                    target_prop=f"z{secrets.token_hex(4)}",
                    force_fail=True,
                )
            )
            for res in (proto_result, control_result):
                res["endpoint"] = endpoint_url
                res["action_name"] = action_name

            probe_results.append(proto_result)
            control_results.append(control_result)

        analysis = analyze_waku_results(
            probe_results,
            endpoints=endpoints_to_probe,
            control_results=control_results,
            react_major=self.get_react_major(detected_versions, detect_context),
            react_version=react_version,
            react_major_confidence=react_major_confidence,
            journal=journal,
        )

        analysis["details"]["detected_versions"] = detected_versions
        return analysis
