# SPDX-FileCopyrightText: 2025 Theori Inc.
# SPDX-License-Identifier: AGPL-3.0-or-later

from __future__ import annotations

from typing import Any
from urllib.parse import urlparse

from ...framework_detection.signals.waku import probe_waku_server_actions_result
from ...http.crawl import crawl_same_origin_html
from ...http.url import build_endpoint_candidates
from .cache import cache_key, resolver_cache
from .types import ActionEndpoint, ActionResolution
from ..snapshots import DetectContext


def _infer_action_name(endpoint_url: str) -> str:
    try:
        path = urlparse(endpoint_url).path
        leaf = path.rstrip("/").split("/")[-1]
        return leaf.split(".", 1)[0]
    except Exception:
        return ""


def _normalize_detected_endpoints(base_url: str, detected_endpoints: list[str]) -> list[ActionEndpoint]:
    out: list[ActionEndpoint] = []
    for endpoint in detected_endpoints:
        if not endpoint:
            continue
        endpoint_str = str(endpoint)
        action_name = _infer_action_name(endpoint_str)
        if endpoint_str.startswith(("http://", "https://")):
            out.append(ActionEndpoint(url=endpoint_str, action_name=action_name))
            continue
        for candidate in build_endpoint_candidates(base_url, endpoint_str):
            out.append(ActionEndpoint(url=candidate, action_name=action_name))
    return out


def _prefer_explicit_action_endpoints(endpoints: list[ActionEndpoint]) -> list[ActionEndpoint]:
    if not endpoints:
        return endpoints
    explicit = [endpoint for endpoint in endpoints if "/RSC/F/" in endpoint.url or "/RSC/ACTION_" in endpoint.url]
    return explicit or endpoints


def resolve_waku_action_endpoints(
    base_url: str,
    detect_context: DetectContext | None,
    *,
    crawl_when_missing: bool = True,
) -> ActionResolution:
    """
    Resolve Waku Server Action endpoint URLs.

    Strategy:
    1) Prefer detector-provided invocation_endpoints.
    2) Else probe the base page for action endpoints.
    3) Else (optional) bounded crawl and re-probe pages until endpoints are found.
    """
    cache = resolver_cache()
    ck = cache_key("waku_action_endpoints", str(base_url))
    cached = cache.get(ck)
    if isinstance(cached, ActionResolution):
        return cached

    detected_endpoints = list(detect_context.invocation_endpoints if detect_context else [])
    endpoints = _normalize_detected_endpoints(base_url, [str(e) for e in detected_endpoints if e])
    if endpoints:
        deduped = list(dict.fromkeys(endpoints))
        out = ActionResolution(
            endpoints=_prefer_explicit_action_endpoints(deduped),
            has_actions=True,
            entrypoint_url=None,
            discovery_method="detect_context",
        )
        cache[ck] = out
        return out

    probe = probe_waku_server_actions_result(base_url)
    if probe.endpoints:
        endpoints: list[ActionEndpoint] = []
        for endpoint_path, action_name in probe.endpoints:
            for candidate in build_endpoint_candidates(base_url, endpoint_path):
                endpoints.append(ActionEndpoint(url=candidate, action_name=action_name))
        endpoints = _prefer_explicit_action_endpoints(list(dict.fromkeys(endpoints)))
        out = ActionResolution(
            endpoints=endpoints,
            has_actions=bool(probe.has_actions),
            entrypoint_url=base_url,
            discovery_method="probe",
            error_info=probe.error_info,
        )
        cache[ck] = out
        return out

    if probe.error_info:
        out = ActionResolution(
            endpoints=[],
            has_actions=bool(probe.has_actions),
            entrypoint_url=base_url,
            discovery_method="probe_error",
            error_info=probe.error_info,
        )
        cache[ck] = out
        return out

    if crawl_when_missing and base_url:
        for page in crawl_same_origin_html(base_url, follow_links=True):
            if not page.url or page.url == base_url:
                continue
            probe2 = probe_waku_server_actions_result(page.url)
            if not probe2.endpoints:
                continue
            endpoints = []
            for endpoint_path, action_name in probe2.endpoints:
                for candidate in build_endpoint_candidates(page.url, endpoint_path):
                    endpoints.append(ActionEndpoint(url=candidate, action_name=action_name))
            if endpoints:
                endpoints = _prefer_explicit_action_endpoints(list(dict.fromkeys(endpoints)))
                out = ActionResolution(
                    endpoints=endpoints,
                    has_actions=bool(probe2.has_actions),
                    entrypoint_url=page.url,
                    discovery_method="crawl_probe",
                    error_info=probe2.error_info,
                )
                cache[ck] = out
                return out

    out = ActionResolution(endpoints=[], has_actions=False, entrypoint_url=None, discovery_method="none")
    cache[ck] = out
    return out


__all__ = ["resolve_waku_action_endpoints"]
